---
title: "SNICSer method comparison"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

This report compares data for a suite of wheels analyzed with the production
version of SNICSer (2.84) with results from the same wheels analyzed with a new
version of SNICSer (2.92) that includes the following changes to the blank correction
method:

1. Mass balance correction for all samples
2. Large blank average from wheel instead of long-term average for small samples
3. Total_mass instead of target_mass
4. Subtract mass of blank from total mass to get mass of unknown in MBC functions
5. New parameters for mass balance correction
6. Mass error from dc13 table
   

This method was used to analyse test wheels:

1. Load wheels in prod version of snicser
2. inherit 1st analyst's flags
3. save analysis to file
4. load wheel from file in test version
5. load saved analysis
6. blank correct
7. first authorize

The same normalization method, flagging, and large wheel blank values are used for both runs. I confirmed that norm_ratio, int_err, ext_err, lg_blk_fm, and sig_lg_blk_fm are the same for both analyses. fm_corr and sig_fm_corr are the same for all large samples, but differs for small samples due to the change in method.

```{r}
library(tidyverse)
library(here)
library(readxl)

options(digits = 5)
```

## Load data

I removed all normalizing standards and ceylon since they don't get the new MBC.

```{r}
data <- read_csv(here("data/SNICSer_blank_compare.csv")) %>% 
  filter(sample_type != "S",
         rec_num != 148820) %>%
  mutate(Name = str_trunc(sample_name, 15, "right"))
```

## Differences between BC methods

Differences are given as production result - test result.

### Large blank differences

Differences in the large blank corrected Fm are due to changing from long term average blank to values from the wheel. There's a small difference in in a few other wheels, but nothing greater than 1E-6. 

```{r}
lbc_diff <- data %>%
  pivot_wider(c(wheel, wheel_pos, ss, tp_num), 
              names_from = table, values_from = fm_corr) %>%
  mutate(fm_diff = snics_results - snics_results_test)

lbc_diff %>%
  filter(!near(snics_results, snics_results_test, tol = 1E-06)) %>%
  arrange(-abs(fm_diff))
```

Using large blanks from the wheel rather than stored values leads to differences in LBC Fm of up to `r max(lbc_diff$fm_diff)` for small samples.


### MBC Fm differences

The table below shows the differences in reported Fm between methods for all samples. Samples that did not get a MBC with the new method (primaries, Ceylon, and samples without MBC parameters) are not included. 

```{r}
all_diff <- data %>%
  pivot_wider(c(wheel, wheel_pos, Name, mass), 
              names_from = table, values_from = c(Fm_reported, sig_Fm_reported)) %>%
  mutate(fm_diff = Fm_reported_snics_results - Fm_reported_snics_results_test,
         sig_fm_diff = sig_Fm_reported_snics_results - sig_Fm_reported_snics_results_test,
         Fm = (Fm_reported_snics_results + Fm_reported_snics_results_test) / 2) %>% 
  filter(!is.na(fm_diff)) %>% 
  arrange(-abs(fm_diff))

all_diff

summarize(all_diff, mean_diff = mean(fm_diff), mean_err_diff = mean(sig_fm_diff))
```

The largest differences are among small and old samples.

```{r}
all_diff %>% 
  ggplot(aes(fm_diff)) +
  geom_histogram()
```
```{r}
all_diff %>% 
  mutate(Fm = (snics_results + snics_results_test) / 2) %>% 
  ggplot(aes(Fm, fm_diff, color = log(mass))) +
  geom_point()
```


```{r}
all_diff %>% 
  mutate(Fm = (snics_results + snics_results_test) / 2) %>% 
  ggplot(aes(log(mass, base = 10), fm_diff, color = Fm)) +
  geom_point()
```
```{r}
all_diff %>% 
  mutate(z_score = sigma(snics_results_test, snics_results, 
```

## Validation of calculations 

This section compares the new SNICSer calculations to what should be the same mass balance calculations done outside of SNICSer using R and Excel (provided by Mark). Mark and I have both seen small differences before. The cause of the differences is uncertain, but they are small and do not significantly affect results.

```{r}
r_comp <- data %>%
  filter(table == "snics_results_test") %>%
  mutate(fm_diff = fm_mb_corr - fm_mb_corr_r) %>%
  select(wheel, wheel_pos, mass, fm_mb_corr, fm_mb_corr_r, fm_diff) %>%
  arrange(desc(fm_diff))
```

MBC done with R matches the new SNICSer. The largest difference is `r max(r_comp$fm_diff)`.

#### MR Excel data

This section is a placeholder using a comparison Mark did in April. The differences should disappear with updated comparison data.

```{r}
data %>%
  filter(!is.na(fm_mb_corr_mr),
         table == "snics_results_test") %>%
  mutate(fm_diff = fm_mb_corr - fm_mb_corr_mr) %>%
  select(wheel, wheel_pos, mass, fm_mb_corr, fm_mb_corr_mr, fm_diff) %>%
  arrange(desc(abs(fm_diff)))
```


## Comparison with consensus

Here I'm looking at only samples with a consensus value.

```{r}
cons_data <- data %>% 
  filter(!is.na(fm_consensus))
```

This table shows difference in normalized agreement with consensus for all samples. Normalized Fm is 
$$ \frac{Fm_{meas} - Fm_{cons}}{Fm_{cons}} $$


```{r}
cons_data %>%
  pivot_wider(c(wheel, wheel_pos, Name, mass, fm_consensus), 
              names_from = table, values_from = sigma) %>%
  mutate(norm_fm_diff = snics_results - snics_results_test) %>%
  arrange(-abs(norm_fm_diff))
```

This is the same data, except using sigma to compare. I haven't looked at error yet, but it should be larger with MBC, therefore sigma should be smaller.

```{r}
cons_data  %>%
  pivot_wider(c(wheel, wheel_pos, Name, mass, fm_consensus), 
              names_from = table, values_from = sigma) %>%
  mutate(sigma_diff = snics_results - snics_results_test) %>%
  arrange(-abs(sigma_diff))
```

### Consensus differences at low mass and Fm

Agreement with consensus and difference between methods is larger at low mass. I need to look at more small samples to fill this in.

```{r}
cons_data %>%
  filter(fm_mb_corr > 0.1, 
         total_umols_co2 < 500) %>%
  ggplot(aes(total_umols_co2, normFm, color = table)) +
    geom_point()
```

MBC blows up at very low Fm. This is likely due to the behavior of the correction function near Fm = 0, and is very sensitive to MBC parameters. This should be taken into account when revisiting age limits. 

```{r}
cons_data %>%
  ggplot(aes(fm_consensus, normFm, color = table)) +
    geom_point()
```

The same plots using sigma instead of normalized Fm show that increased reported error at low Fm and mass account for the variability of these samples.
```{r}
cons_data %>%
  filter(fm_mb_corr > 0.1, 
         total_umols_co2 < 500) %>%
  ggplot(aes(total_umols_co2, sigma, color = table)) +
    geom_point()
```

MBC blows up at very low Fm. This is likely due to the behavior of the correction function near Fm = 0, and is very sensitive to MBC parameters. This should be taken into account when revisiting age limits. 

```{r}
cons_data %>%
  ggplot(aes(fm_consensus, sigma, color = table)) +
    geom_point()
```

### Mean agreement with consensus

Compare average agreement with consensus for Fm > 0.02 for new and old methods.

The table below includes only small samples that got MBC with both methods.

```{r}
cons_data %>%
  filter(fm_mb_corr > 0.02,
         ss == 1) %>%
  group_by(table) %>%
    summarize("Mean normalized Fm" = mean(normFm),
              "SD of norm Fm" = sd(normFm),
              "Sigma of Fm" = mean(sigma),
              "SD of Sigma" = sd(sigma),
              N = n())
```

This table is all known-value samples, including large samples that got only LBC with the old method and now get MBC.


```{r}
cons_data %>%
  filter(fm_consensus > 0.1) %>%
  group_by(table) %>%
    summarize("Mean normalized Fm" = mean(normFm),
              "SD of norm Fm" = sd(normFm),
              "Sigma of Fm" = mean(sigma),
              "SD of Sigma" = sd(sigma),
              N = n())
```