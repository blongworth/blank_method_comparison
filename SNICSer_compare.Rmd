---
title: "SNICSer method comparison"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Compare data from wheels analysed with the production version of SNICSer with data from the new blank methods used by the test version 2.90.

First pass: USAMS030520 and CFAMS031020.

Started with clean test tables and read data from results files

1. Load wheels in prod version of snicser
2. inherit 1st analyst's flags
3. save analysis to file
4. load wheel from file in test version
5. load saved analysis
6. blank correct
7. first authorize

Need to check to make sure same norm method is chosen, and that same blanks are chosen for LBC in blank corr.

Not using CFAMS20120, which was Ulrich's test wheel.

```{r}
library(amstools)
library(odbc)
library(glue)
library(tidyverse)
library(here)
library(readxl)
```

## Get data


```{r}
whdata <- read_csv(here("data/results.csv"))
data <- read_csv(here("data/SNICSer_blank_compare.csv"))
unique(whdata$wheel)
```

## Find data issues

Just sanity checking to make sure SNICSer's working and that we're looking at the right data.

### Compare normalization method

No rows mean all wheels use the same norm method for both test and production.

```{r}
data %>%
  pivot_wider(id_cols = c("wheel", "wheel_pos"), names_from = "table", values_from = "norm_method") %>%
  filter(snics_results != snics_results_test)
```


#### LBC Parameters

Look at LBC values by wheel. I haven't been able to figure out what causes some
of the differences. It's possible the wheel values were edited manually. I ended
up going into these wheels in snicser and fixing the values that differed by
more than 0.000001. Need to remember that small samples get book values

* CFAMS020620, flag Kauri wood
* CFAMS021120, leave Praxair unflagged
* CFAMS021820, Kauri included in original analysis by mistake
* CFAMS022620, Couldn't flag to produce original values, DB values from orig. copied




```{r}
# Check that LB values are the same
data %>%
  pivot_wider(id_cols = c("wheel", "wheel_pos", "process", "ss"), names_from = "table", values_from = "lg_blk_fm") %>%
  arrange(wheel, process, wheel_pos) %>%
  filter(!near(snics_results, snics_results_test, tol = 1E-6),
         ss == 0)

# Check that LB errors are the same
data %>%
  pivot_wider(id_cols = c("wheel", "wheel_pos", "process", "ss"), names_from = "table", values_from = "sig_lg_blk_fm") %>%
  filter(!near(snics_results, snics_results_test, tol = 1E-6),
         ss == 0)
```

#### Norm ratio

A few results have slightly different norm_ratios, but all look like some kind of internal rounding error. No results different at > 1E-15.

```{r}
data %>%
  pivot_wider(c(wheel, wheel_pos, ss, tp_num), 
              names_from = table, values_from = norm_ratio) %>%
  mutate(fm_diff = snics_results - snics_results_test) %>%
  filter(!near(snics_results, snics_results_test, tol = 1E-15))
```

## Differences due to new methods

Everything here should be due to changes in blank cor method, not due to changes in analysis.

### Large blank differences

All differences > 1E-5 in fm_corr are due to changing from long term lg_blk_fm to values from the wheel. There's a small difference in in a few other wheels, but nothing greater than 1E-6.

```{r}
data %>%
  pivot_wider(c(wheel, wheel_pos, ss, tp_num), 
              names_from = table, values_from = lg_blk_fm) %>%
  mutate(fm_diff = snics_results - snics_results_test)  %>%
  filter(!near(snics_results, snics_results_test, tol = 1E-06)) %>%
  arrange(-abs(fm_diff))
```

This leads to discrepancies in fm_corr of up to 0.0028 for small samples.

```{r}
data %>%
  pivot_wider(c(wheel, wheel_pos, ss, tp_num), 
              names_from = table, values_from = fm_corr) %>%
  mutate(fm_diff = snics_results - snics_results_test)  %>%
  filter(!near(snics_results, snics_results_test, tol = 1E-06)) %>%
  arrange(-abs(fm_diff))
```

### MBC differences

#### Small samples

Here are the differences between methods for small samples. Keep in mind that some of this is driven by the different lg_blk_fm used for LBC for these samples.

```{r}
data %>%
  pivot_wider(c(wheel, wheel_pos, ss, tp_num), 
              names_from = table, values_from = fm_mb_corr) %>%
  mutate(fm_diff = snics_results - snics_results_test)  %>%
  filter(!near(snics_results, snics_results_test, tol = 1E-06), ss == 1) %>%
  arrange(-abs(fm_diff))
```

SNICSer now handles missing MBC parameters by setting the MBC fields in snics_results to Null. This should make it easy to turn MBC on and off with the parameters in dc13.

```{r}
data %>%
  pivot_wider(c(wheel, wheel_pos), 
              names_from = table, values_from = fm_mb_corr) %>%
  mutate(both_NA = is.na(snics_results) & is.na(snics_results_test)) %>%
  filter(is.na(snics_results_test)) %>%
  arrange(wheel, wheel_pos)
```


#### Large samples

Here are the differences in final fm for large samples not including -99s.

```{r}
data %>%
  filter(#ss == 1,
         table == "snics_results",
         fm_mb_corr == 0 | is.na(fm_mb_corr))
data %>%
  filter(ss == 0) %>%
  mutate(Fmodern = ifelse(is.na(fm_mb_corr) | fm_mb_corr == 0, fm_corr, fm_mb_corr)) %>%
  pivot_wider(c(wheel, wheel_pos, tp_num), 
              names_from = table, values_from = Fmodern) %>%
  mutate(fm_diff = snics_results - snics_results_test) %>%
  filter(snics_results_test > -1) %>%
  arrange(-abs(fm_diff))
```

## Comparison with MBC blank cor in R and Excel

This section compares the new SNICSer calculations to what should be the same calculation done in R. Mark and I have both seen small differences before, likely due to rounding errors. Just looking at CFAMS031020 to start.

TODO: Move to get_snicser_data.R

```{r}
# Function to get data from dc13_test
getdc13test <- function(tps) {
con <- conNOSAMS()
  sql <- glue::glue_sql("SELECT * FROM dc13_test WHERE tp_num IN ({tp*})",
                  tp = tps,
                  .con = con)
  query <- odbc::dbSendQuery(con, sql)
  data <- odbc::dbFetch(query)
  odbc::dbClearResult(query)
  data
}

dc13 <- getdc13(data$tp_num)
data %>%
  left_join(dc13, by = "tp_num") %>% 
  select(process, fm_blank)
# get data from snics_results
con <- conNOSAMS()
#d <- getWheel("CFAMS031020", test = TRUE) %>%
d <- getWheel(wheels, test = TRUE) %>%
  filter(fm_mb_corr > 0.05)
# get info from dc13
dc13 <- getdc13(d$tp_num)
cf031020 <- d %>%
  left_join(dc13, by = "tp_num") %>% 
  mutate(total_ug_co2 = total_umols_co2 * 12.015,
         graphite_ug_co2 = graphite_umols_co2 * 12.015,
         unknown_ug_co2 = graphite_ug_co2 - mass_cont,
         measmasserr = ifelse(is.na(sig_tot_umols), 
                              graphite_ug_co2 * .1, sig_tot_umols))

# Do MBC
cf031020  <- cf031020  %>%
        mutate(fmMBcor = pmap_dbl(list(.$fm_corr, .$fm_cont, 
                                   .$total_ug_co2, .$mass_cont), 
                              doMBC),
               fmMBcorerr = pmap_dbl(list(.$fm_corr, .$fm_cont, 
                                      .$total_ug_co2, .$mass_cont, 
                                      .$sig_fm_corr, .$fm_cont_err, 
                                      .$sig_tot_umols, .$mass_cont_err), doMBCerr))
```

```{r}
cf031020 %>%
  select(wheel_pos, fm_corr, sig_fm_corr, fm_mb_corr, sig_fm_mb_corr, fmMBcor, fmMBcorerr)
```

```{r}
normDiff <- function(x, y) {
  mean <- (x + y) / 2
  (x - mean) / mean
}

cf031020s <- cf031020 %>%
  filter(fm_mb_corr > 0.1) %>%
  mutate(snfm = normDiff(fm_mb_corr, fmMBcor),
         rfm = normDiff(fmMBcor, fm_mb_corr)) %>%
  select(wheel_pos, sample_name, total_umols_co2, fm_corr, snfm, rfm)
```

These samples have the largest differences

```{r}
cf031020s %>%
  pivot_longer(c(snfm, rfm), names_to = "method", values_to = "Fm") %>%
  filter(abs(Fm) > 0.005) %>%
  ggplot(aes(sample_name, Fm, color = method)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Fm versus diff in method

```{r}
cf031020s %>%
  filter(total_umols_co2 > 15) %>%
ggplot(aes(fm_corr, snfm)) +
  geom_point()
```

Size versus diff in method

```{r}
ggplot(cf031020s, aes(total_umols_co2, snfm)) +
  geom_point() +
  #ylim(-0.001, 0.001) +
  xlim(0, 50)
```

#### MR Excel data

```{r}
mrdata <- read_excel(here("data/CFAMS03102 MBC Test Results.xlsx"), skip = 3, col_names = FALSE) %>%
  .[c(3, 25, 26)] %>%
  rename(tp_num = "...3",
         mrbcfm = "...25",
         mrbcfmerr = "...26")

cf031020 %>%
  filter(wheel == "CFAMS031020") %>%
  pivot_wider(c(tp_num, wheel_pos), 
              names_from = table, values_from = fm_mb_corr) %>%
  mutate(both_NA = is.na(snics_results) & is.na(snics_results_test)) %>%
  arrange(wheel_pos) %>%
  inner_join(mrdata)
```

### Comparison with consensus

Here I'm looking at only standards that we have a known value for in the DB.

Compare just small samples with previous and new MBC

```{r}
# get consensus values
cons <- getStdTable() %>%
  select(rec_num, fm_consensus)

# merge with data by tp. Keep only standards
consdata <- inner_join(data, cons, by = "rec_num") %>%
  filter(sample_type != "S") %>%
  mutate(Fmodern = ifelse(is.na(fm_mb_corr), fm_corr, fm_mb_corr),
         FmErr = ifelse(is.na(sig_fm_mb_corr), sig_fm_corr, sig_fm_mb_corr),
         normFm = normFm(Fmodern, fm_consensus),
         sigma = sigma(Fmodern, fm_consensus, FmErr))

consdata %>%
  group_by(table) %>%
  summary()
```

Fm disagreement with consensus blows up at very low Fm and with some samples < 250 umol. 

```{r}
consdata %>%
  filter(fm_mb_corr > 0.1, total_umols_co2 < 500) %>%
ggplot(aes(total_umols_co2, normFm, color = table)) +
  geom_point()
consdata %>%
  #filter(Fmodern > 0.1) %>%
ggplot(aes(fm_consensus, normFm, color = table)) +
  geom_point()
consdata %>%
  filter(fm_mb_corr > 0.1) %>%
ggplot(aes(fm_consensus, normFm, color = table)) +
  geom_point()
```

Compare average agreement with consensus for Fm > 0.1 for new and old methods

```{r}
consdata %>%
  filter(fm_mb_corr > 0.1,
         ss == 1) %>%
  group_by(table) %>%
    summarize("Mean normalized Fm" = mean(normFm),
              "SD of norm Fm" = sd(normFm),
              "Sigma of Fm" = mean(sigma),
              "SD of Sigma" = sd(sigma),
              N = n())
```

Compare old and new, including large samples that now get MBC.

```{r}
consdata %>%
  filter(Fmodern > 0.1) %>%
  group_by(table) %>%
    summarize("Mean normalized Fm" = mean(normFm),
              "SD of norm Fm" = sd(normFm),
              "Sigma of Fm" = mean(sigma),
              "SD of Sigma" = sd(sigma),
              N = n())
```